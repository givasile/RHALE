@inproceedings{molnar2020interpretable,
  title={Interpretable machine learning--a brief history, state-of-the-art and challenges},
  author={Molnar, Christoph and Casalicchio, Giuseppe and Bischl, Bernd},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={417--431},
  year={2020},
  organization={Springer}
}


@article{molnar2020model,
  title={Model-agnostic Feature Importance and Effects with Dependent Features--A Conditional Subgroup Approach},
  author={Molnar, Christoph and K{\"o}nig, Gunnar and Bischl, Bernd and Casalicchio, Giuseppe},
  journal={arXiv preprint arXiv:2006.04628},
  year={2020}
}

@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}

@inproceedings{molnar2022general,
  title={General pitfalls of model-agnostic interpretation methods for machine learning models},
  author={Molnar, Christoph and K{\"o}nig, Gunnar and Herbinger, Julia and Freiesleben, Timo and Dandl, Susanne and Scholbeck, Christian A and Casalicchio, Giuseppe and Grosse-Wentrup, Moritz and Bischl, Bernd},
  booktitle={International Workshop on Extending Explainable AI Beyond Deep Models and Classifiers},
  pages={39--68},
  year={2022},
  organization={Springer}
}

@inproceedings{herbinger2022repid,
  title={REPID: Regional Effect Plots with implicit Interaction Detection},
  author={Herbinger, Julia and Bischl, Bernd and Casalicchio, Giuseppe},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10209--10233},
  year={2022},
  organization={PMLR}
}

@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={6},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{apley2020visualizing,
  title={Visualizing the effects of predictor variables in black box supervised learning models},
  author={Apley, Daniel W and Zhu, Jingyu},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={82},
  number={4},
  pages={1059--1086},
  year={2020},
  publisher={Wiley Online Library}
}

@article{friedman2001greedy,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@article{goldstein2015peeking,
  title={Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation},
  author={Goldstein, Alex and Kapelner, Adam and Bleich, Justin and Pitkin, Emil},
  journal={journal of Computational and Graphical Statistics},
  volume={24},
  number={1},
  pages={44--65},
  year={2015},
  publisher={Taylor \& Francis}
}

@misc{Gromping2020MAEP,
author = {Grömping, Ulrike},
year = {2020},
month = {03},
pages = {},
title = {Model-Agnostic Effects Plots for Interpreting Machine Learning Models}
}

@article{aas2021explaining,
  title={Explaining individual predictions when features are dependent: More accurate approximations to Shapley values},
  author={Aas, Kjersti and Jullum, Martin and L{\o}land, Anders},
  journal={Artificial Intelligence},
  volume={298},
  pages={103502},
  year={2021},
  publisher={Elsevier}
}

@article{britton2019vine,
  title={Vine: visualizing statistical interactions in black box models},
  author={Britton, Matthew},
  journal={arXiv preprint arXiv:1904.00561},
  year={2019}
}

@article{friedman2008predictive,
  title={Predictive learning via rule ensembles},
  author={Friedman, Jerome H and Popescu, Bogdan E},
  journal={The annals of applied statistics},
  pages={916--954},
  year={2008},
  publisher={JSTOR}
}

@article{greenwell2018simple,
  title={A simple and effective model-based variable importance measure},
  author={Greenwell, Brandon M and Boehmke, Bradley C and McCarthy, Andrew J},
  journal={arXiv preprint arXiv:1805.04755},
  year={2018}
}

@article{lundberg2018consistent,
  title={Consistent individualized feature attribution for tree ensembles},
  author={Lundberg, Scott M and Erion, Gabriel G and Lee, Su-In},
  journal={arXiv preprint arXiv:1802.03888},
  year={2018}
}


@article{baniecki2021fooling,
  title={Fooling Partial Dependence via Data Poisoning},
  author={Baniecki, Hubert and Kretowicz, Wojciech and Biecek, Przemyslaw},
  journal={arXiv preprint arXiv:2105.12837},
  year=2021
}

@article{pace1997sparse,
  title={Sparse spatial autoregressions},
  author={Pace, R Kelley and Barry, Ronald},
  journal={Statistics \& Probability Letters},
  volume={33},
  number={3},
  pages={291--297},
  year={1997},
  publisher={Elsevier}
}


@article{gkolemis22,
    title = {DALE: Differential Accumulated Local Effects for efficient and accurate global explanations},
    author = {Gkolemis, Vasilis and Dalamagas, Theodore and Diou, Christos},
    journal = {arXiv preprint arXiv:2210.04542},
    year = {2022}
    }


@article{wiens2019no,
  title={Do no harm: a roadmap for responsible machine learning for health care},
  author={Wiens, Jenna and Saria, Suchi and Sendak, Mark and Ghassemi, Marzyeh and Liu, Vincent X and Doshi-Velez, Finale and Jung, Kenneth and Heller, Katherine and Kale, David and Saeed, Mohammed and others},
  journal={Nature medicine},
  volume={25},
  number={9},
  pages={1337–1340},
  year={2019},
  publisher={Nature Publishing Group US New York} }


@article{molnar2021relating,
  title={Relating the partial dependence plot and permutation feature importance to the data generating process},
  author={Molnar, Christoph and Freiesleben, Timo and K{\"o}nig, Gunnar and Casalicchio, Giuseppe and Wright, Marvin N and Bischl, Bernd},
  journal={arXiv preprint arXiv:2109.01433},
  year={2021}
}

@article{freiesleben2022scientific,
  title={Scientific inference with interpretable machine learning: Analyzing models to learn about real-world phenomena},
  author={Freiesleben, Timo and K{\"o}nig, Gunnar and Molnar, Christoph and Tejero-Cantero, Alvaro},
  journal={arXiv preprint arXiv:2206.05487},
  year={2022}
}

@inproceedings{ribeiro2016should,
  title={{"Why should i trust you?" Explaining the predictions of any classifier}},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International conference on machine learning},
  pages={1885--1894},
  year={2017},
  organization={PMLR}
}

@inproceedings{casalicchio2019visualizing,
  title={Visualizing the feature importance for black box models},
  author={Casalicchio, Giuseppe and Molnar, Christoph and Bischl, Bernd},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10--14, 2018, Proceedings, Part I 18},
  pages={655--670},
  year={2019},
  organization={Springer}
}

@article{kim2016examples,
  title={Examples are not enough, learn to criticize! criticism for interpretability},
  author={Kim, Been and Khanna, Rajiv and Koyejo, Oluwasanmi O},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
